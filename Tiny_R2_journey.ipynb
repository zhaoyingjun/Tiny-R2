{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhaoyingjun/Tiny-R2/blob/main/Tiny_R2_journey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc_r5BxfJBoB",
        "outputId": "82d407c7-5024-4ac0-864e-6c4949c454f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting git+https://github.com/KellerJordan/Muon\n",
            "  Cloning https://github.com/KellerJordan/Muon to /tmp/pip-req-build-2cg4gev7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/KellerJordan/Muon /tmp/pip-req-build-2cg4gev7\n",
            "  Resolved https://github.com/KellerJordan/Muon to commit 6399c658d3c4a3356ba823fa6664b10e23871068\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: muon-optimizer\n",
            "  Building wheel for muon-optimizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for muon-optimizer: filename=muon_optimizer-0.1.0-py3-none-any.whl size=7141 sha256=e2cef19c4e1f8a8316ae2ccf6977eff6214641dba0ff255ce8e2fcf5f4fe8c53\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mhb6q5c_/wheels/6e/33/94/64d18603ba0f39064aab523d6edf493c388cfb7419bb5c9043\n",
            "Successfully built muon-optimizer\n",
            "Installing collected packages: muon-optimizer\n",
            "Successfully installed muon-optimizer-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken datasets transformers huggingface_hub\n",
        "!pip install git+https://github.com/KellerJordan/Muon\n",
        "\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import hf_hub_download, list_repo_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUvpQeqrNb5S",
        "outputId": "ed4b76f1-208b-47c3-f50b-525a13fc0c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tiny-R2'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 130 (delta 69), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (130/130), 83.76 KiB | 4.93 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n",
            "/content/Tiny-R2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zhaoyingjun/Tiny-R2.git\n",
        "%cd Tiny-R2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zu9Mi4rNvOy"
      },
      "outputs": [],
      "source": [
        "!python train.py  --n_layer 6 --n_embd 512 --hc 'Ture' --mhc 'True' --max_iters 300 --attention_types 'DSA' 'DSA' 'DSA'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mv0zEu2RuaGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ca0b45-e8f4-4f9b-fa8d-5e0cf0142731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python train.py --n_layer 6 --n_embd 512 --hc 'False' --max_iters 300 --attention_types 'DSA' 'DSA' 'DSA'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1YpGC3aAud4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e09486-c89b-4eee-c6a5-68de5e466762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python train.py --n_layer 6 --n_embd 512 --hc 'True' --mhc 'Ture' --max_iters 300 --attention_types 'full' 'full' 'full'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f77H8c5Tujt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ee2853-9309-48a0-8c18-d38274488322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python train.py --n_layer 6 --n_embd 512 --hc 'False' --max_iters 300 --attention_types 'full' 'full' 'full'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwS3ArkpunOn"
      },
      "outputs": [],
      "source": [
        "!python train.py --n_layer 6 --n_embd 512 --hc 'True' --mhc 'Ture' --max_iters 3000 --attention_types 'DSA' 'DSA' 'full'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYXlsDlguqfW"
      },
      "outputs": [],
      "source": [
        "!python train.py --n_layer 6 --n_embd 512 --hc 'False' --max_iters 300 --attention_types 'DSA' 'DSA' 'full'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSBOIHOauthf"
      },
      "outputs": [],
      "source": [
        "!python train.py --n_layer 6 --n_embd 512 --hc 'True' --mhc 'False' --max_iters 300 --attention_types 'DSA' 'DSA' 'DSA'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp_F6H6swPDr"
      },
      "outputs": [],
      "source": [
        "!python train.py --n_layer 6 --n_embd 512 --hc 'True' --mhc 'False' --max_iters 300 --attention_types 'full' 'full' 'full'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hl-7D_DwPLw"
      },
      "outputs": [],
      "source": [
        "!python train.py --n_layer 6 --n_embd 512 --hc 'True' --mhc 'False' --max_iters 300 --attention_types 'DSA' 'DSA' 'full'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYe4AzP-waPf"
      },
      "source": [
        "**mhc-2NSA1Full-DSMoE is Best**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpJ4ea_0wcQf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiJgR6tEvt_u"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7k_z_HKtyql"
      },
      "source": [
        "**è®­ç»ƒä»£ç æ•°æ®ï¼Œå¯ä»¥è®­ç»ƒä¸€ä¸ªpythoné£Žæ ¼çš„ä»£ç å¤§æ¨¡åž‹ï¼Œ1Bå‚æ•°é‡ã€‚**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkv9UPChuw-U"
      },
      "outputs": [],
      "source": [
        "!python train.py --n_layer 12 --n_embd 256 --hc 'False' --mhc 'False' --max_iters 3000 --attention_types 'full' 'full' 'full' --batch_size 16 --ctx_len 2048"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XhnwdXsfo8_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHjJr7eu0zH",
        "outputId": "e9361e82-ce12-410e-d759-3b4cae83b1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myingjun-xuda\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m setting up run oolge9xz (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£¾\u001b[0m setting up run oolge9xz (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£·\u001b[0m setting up run oolge9xz (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.24.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Tiny-R2/wandb/run-20260216_141017-oolge9xz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflytech-python-codes-moe\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/yingjun-xuda/Tiny-R2-code\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yingjun-xuda/Tiny-R2-code/runs/oolge9xz\u001b[0m\n",
            "Loading HF dataset: flytech/python-codes-25k\n",
            "Dataset({\n",
            "    features: ['output', 'instruction', 'input', 'text'],\n",
            "    num_rows: 49626\n",
            "})\n",
            "num Muon parameters: 468,583,264\n",
            "num AdamW parameters: 99,988,048\n",
            "Model compiled with torch.compile\n",
            "\n",
            "============================================================\n",
            "Model & Optimizer Summary\n",
            "============================================================\n",
            "\n",
            "Total trainable parameters: 568.571 M\n",
            "\n",
            "--- Transformer Architecture ---\n",
            "Number of layers: 12\n",
            "Attention heads: 16\n",
            "Embedding size: 384\n",
            "Layer 0: atten=Spares, atten_mode=SWA,ffn=moe\n",
            "Layer 1: atten=FULL, atten_mode=MLA,ffn=moe\n",
            "Layer 2: atten=Spares, atten_mode=DSA,ffn=moe\n",
            "Layer 3: atten=Spares, atten_mode=SWA,ffn=moe\n",
            "Layer 4: atten=FULL, atten_mode=MLA,ffn=moe\n",
            "Layer 5: atten=Spares, atten_mode=DSA,ffn=moe\n",
            "Layer 6: atten=Spares, atten_mode=SWA,ffn=moe\n",
            "Layer 7: atten=FULL, atten_mode=MLA,ffn=moe\n",
            "Layer 8: atten=Spares, atten_mode=DSA,ffn=moe\n",
            "Layer 9: atten=Spares, atten_mode=SWA,ffn=moe\n",
            "Layer 10: atten=FULL, atten_mode=MLA,ffn=moe\n",
            "Layer 11: atten=Spares, atten_mode=DSA,ffn=moe\n",
            "\n",
            "--- MoE Configuration ---\n",
            "Number of experts: 32\n",
            "Active experts per token: 4\n",
            "Shared experts: 1\n",
            "Expert bias enabled: True\n",
            "\n",
            "--- Hyper-connections ---\n",
            "Expand stream: Reduce\n",
            "Reduce stream: Reduce\n",
            "\n",
            "--- Optimizers ---\n",
            "Optimizer 0 (Muon) group 0: lr=0.02, wd=0\n",
            "  -> Muon handles N/A experts\n",
            "Optimizer 1 (AdamW) group 0: lr=1e-06, wd=0.1\n",
            "\n",
            "============================================================\n",
            "\n",
            "ðŸš€ Starting training\n",
            "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py:3546: UserWarning: Mismatch dtype between input and weight: input dtype = c10::Half, weight dtype = float, Cannot dispatch to fused implementation. (Triggered internally at /pytorch/aten/src/ATen/native/layer_norm.cpp:344.)\n",
            "  return node.target(*args, **kwargs)  # type: ignore[operator]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n",
            "[0] train_loss=20.4884 val_loss=19.3716 step_time=151.84s TPS=431.61\n",
            "[20] train_loss=5.7805 val_loss=5.6236 step_time=3.32s TPS=19764.11\n",
            "[40] train_loss=5.6096 val_loss=7.0970 step_time=3.34s TPS=19639.25\n",
            "[60] train_loss=3.5733 val_loss=3.5771 step_time=3.34s TPS=19601.46\n",
            "[80] train_loss=2.9101 val_loss=2.7256 step_time=3.32s TPS=19717.54\n",
            "[100] train_loss=4.2910 val_loss=3.7616 step_time=3.40s TPS=19279.13\n",
            "[120] train_loss=2.3327 val_loss=2.1904 step_time=3.31s TPS=19824.06\n",
            "[140] train_loss=4.9374 val_loss=4.9461 step_time=3.36s TPS=19519.84\n",
            "[160] train_loss=2.0377 val_loss=1.8270 step_time=3.33s TPS=19694.84\n",
            "[180] train_loss=1.5879 val_loss=1.4144 step_time=3.34s TPS=19632.55\n",
            "[200] train_loss=2.5799 val_loss=2.0604 step_time=3.41s TPS=19220.08\n",
            "[220] train_loss=1.2436 val_loss=1.0589 step_time=3.34s TPS=19610.62\n",
            "[240] train_loss=3.7101 val_loss=2.8418 step_time=3.36s TPS=19483.80\n",
            "[260] train_loss=1.1523 val_loss=0.9222 step_time=3.33s TPS=19658.73\n",
            "[280] train_loss=1.0018 val_loss=0.8517 step_time=3.34s TPS=19598.78\n"
          ]
        }
      ],
      "source": [
        "!python train.py --n_layer 12 --n_embd 384 --hc 'True' --mhc 'True' --n_experts 32  --max_iters 10000 --attention_mode 'SWA' 'NSA' 'DSA' --attention_types 'Spares' 'FULL' 'Spares' --batch_size 16 --ctx_len 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIKpEo6Ju4Sh"
      },
      "outputs": [],
      "source": [
        "!python sampler.py --checkpoint checkpoints/check_1400.pt --prompt \"åŒ—äº¬æ˜¯ä¸­å›½çš„\"  --max_new_tokens 100 --temperature 0.7    --top_k 100     --device cuda"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNZxZ0M6p7lnH5Xpj+tBvhQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}