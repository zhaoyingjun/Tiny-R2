{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhaoyingjun/Tiny-R2/blob/main/Tiny_R2_journey.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc_r5BxfJBoB",
        "outputId": "19022cac-f010-44af-fe1c-06b446da6de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (1.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.24.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n",
            "Collecting git+https://github.com/KellerJordan/Muon\n",
            "  Cloning https://github.com/KellerJordan/Muon to /tmp/pip-req-build-vd3798q4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/KellerJordan/Muon /tmp/pip-req-build-vd3798q4\n",
            "  Resolved https://github.com/KellerJordan/Muon to commit 6399c658d3c4a3356ba823fa6664b10e23871068\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: muon-optimizer\n",
            "  Building wheel for muon-optimizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for muon-optimizer: filename=muon_optimizer-0.1.0-py3-none-any.whl size=7141 sha256=5ab056223659d33ec910b2540f1ad9b768abc748f71b0ffba6f9f603be558e01\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5vjp8ef5/wheels/6e/33/94/64d18603ba0f39064aab523d6edf493c388cfb7419bb5c9043\n",
            "Successfully built muon-optimizer\n",
            "Installing collected packages: muon-optimizer\n",
            "Successfully installed muon-optimizer-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken datasets transformers huggingface_hub\n",
        "!pip install git+https://github.com/KellerJordan/Muon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUvpQeqrNb5S",
        "outputId": "39850606-2220-4e91-8e35-263f4a17c5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tiny-R2'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (165/165), done.\u001b[K\n",
            "remote: Total 166 (delta 91), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (166/166), 113.31 KiB | 2.58 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n",
            "/content/Tiny-R2\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zhaoyingjun/Tiny-R2.git\n",
        "%cd Tiny-R2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7k_z_HKtyql"
      },
      "source": [
        "**ËÆ≠ÁªÉopenwebtextÊï∞ÊçÆÔºåÂèØ‰ª•ËÆ≠ÁªÉ‰∏Ä‰∏™Âü∫Á°ÄÂ§ßÊ®°ÂûãÔºå0.6BÂèÇÊï∞ÈáèÔºåËØÑÊµãÊ®°ÂûãÁªìÊûÑÂíåÊïàÊûú„ÄÇ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZHjJr7eu0zH",
        "outputId": "81e5f455-aefb-409f-eae6-0d45c09798c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found latest checkpoint: checkpoints/best_model_step_2180.pt (step 2180)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myingjun-xuda\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run dpozko59 (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run dpozko59 (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m setting up run dpozko59 (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m setting up run dpozko59 (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m setting up run dpozko59 (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.25.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Tiny-R2/wandb/run-20260225_071351-dpozko59\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mopenwebtext\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/yingjun-xuda/Tiny-R2-openweb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/yingjun-xuda/Tiny-R2-openweb/runs/dpozko59\u001b[0m\n",
            "Loading HF dataset: Skylion007/openwebtext\n",
            "Resolving data files: 100% 80/80 [00:00<00:00, 451000.43it/s]\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "Resolving data files: 100% 80/80 [00:00<00:00, 469292.76it/s]\n",
            "Loading dataset shards: 100% 80/80 [00:00<00:00, 3352.49it/s]\n",
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 8013769\n",
            "})\n",
            "num Muon parameters: 471,175,008\n",
            "num AdamW parameters: 140,319,312\n",
            "Loading checkpoint from: checkpoints/best_model_step_2180.pt\n",
            "Resumed from iteration 2180\n",
            "Best val loss so far: 1.7825\n",
            "Training history: 2181 train steps, 110 eval steps\n",
            "Restored WandB run ID: e2oj5d0e\n",
            "Model compiled with torch.compile\n",
            "\n",
            "============================================================\n",
            "Model & Optimizer Summary\n",
            "Resuming from iteration 2181/10000\n",
            "Best validation loss so far: 1.7825\n",
            "============================================================\n",
            "\n",
            "Total trainable parameters: 611.494 M\n",
            "\n",
            "--- Transformer Architecture ---\n",
            "Number of layers: 12\n",
            "Attention heads: 16\n",
            "Embedding size: 384\n",
            "Layer 0: atten=Spares, atten_mode=SWA, ffn=moe\n",
            "Layer 1: atten=Spares, atten_mode=NSA, ffn=moe\n",
            "Layer 2: atten=Spares, atten_mode=DSA, ffn=moe\n",
            "Layer 3: atten=Spares, atten_mode=SWA, ffn=moe\n",
            "Layer 4: atten=Spares, atten_mode=NSA, ffn=moe\n",
            "Layer 5: atten=Spares, atten_mode=DSA, ffn=moe\n",
            "Layer 6: atten=Spares, atten_mode=SWA, ffn=moe\n",
            "Layer 7: atten=Spares, atten_mode=NSA, ffn=moe\n",
            "Layer 8: atten=Spares, atten_mode=DSA, ffn=moe\n",
            "Layer 9: atten=Spares, atten_mode=SWA, ffn=moe\n",
            "Layer 10: atten=Spares, atten_mode=NSA, ffn=moe\n",
            "Layer 11: atten=Spares, atten_mode=DSA, ffn=moe\n",
            "\n",
            "--- MoE Configuration ---\n",
            "Number of experts: 32\n",
            "Active experts per token: 8\n",
            "Shared experts: 1\n",
            "Expert bias enabled: True\n",
            "\n",
            "--- Hyper-connections ---\n",
            "Expand stream: Reduce\n",
            "Reduce stream: Reduce\n",
            "\n",
            "--- Optimizers ---\n",
            "Optimizer 0 (Muon) group 0: lr=0.02, wd=0\n",
            "  -> Muon handles N/A experts\n",
            "Optimizer 1 (AdamW) group 0: lr=9.262195564942699e-06, wd=0.1\n",
            "\n",
            "============================================================\n",
            "\n",
            "üöÄ Resuming training from iteration 3181\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py:3694: UserWarning: Mismatch dtype between input and weight: input dtype = c10::Half, weight dtype = float, Cannot dispatch to fused implementation. (Triggered internally at /pytorch/aten/src/ATen/native/layer_norm.cpp:344.)\n",
            "  return node.target(*args, **kwargs)  # type: ignore[operator]\n",
            "[3200] train_loss=2.6735 val_loss=1.7991 best_val_loss=1.7825 step_time=5.42s TPS=36268.04 lr=0.000009\n",
            "[3220] train_loss=2.6041 val_loss=2.2695 best_val_loss=1.7825 step_time=5.41s TPS=36360.01 lr=0.000009\n",
            "[3240] train_loss=3.5957 val_loss=2.4334 best_val_loss=1.7825 step_time=5.43s TPS=36184.68 lr=0.000009\n",
            "[3260] train_loss=3.4446 val_loss=2.5702 best_val_loss=1.7825 step_time=5.43s TPS=36208.37 lr=0.000009\n",
            "[3280] train_loss=3.4945 val_loss=2.4364 best_val_loss=1.7825 step_time=5.43s TPS=36201.65 lr=0.000009\n",
            "[3300] train_loss=3.0525 val_loss=2.0541 best_val_loss=1.7825 step_time=5.45s TPS=36061.65 lr=0.000009\n",
            "[3320] train_loss=2.9887 val_loss=1.9631 best_val_loss=1.7825 step_time=5.45s TPS=36107.76 lr=0.000009\n",
            "[3340] train_loss=3.5939 val_loss=2.6532 best_val_loss=1.7825 step_time=5.45s TPS=36045.78 lr=0.000009\n",
            "[3360] train_loss=4.0489 val_loss=2.8587 best_val_loss=1.7825 step_time=5.44s TPS=36115.92 lr=0.000009\n",
            "[3380] train_loss=3.1069 val_loss=2.1629 best_val_loss=1.7825 step_time=5.45s TPS=36101.22 lr=0.000009\n",
            "[3400] train_loss=2.9449 val_loss=2.1889 best_val_loss=1.7825 step_time=5.44s TPS=36136.55 lr=0.000009\n",
            "[3420] train_loss=3.1096 val_loss=1.9899 best_val_loss=1.7825 step_time=5.45s TPS=36090.67 lr=0.000009\n",
            "[3440] train_loss=6.2949 val_loss=5.2014 best_val_loss=1.7825 step_time=5.46s TPS=35989.71 lr=0.000009\n",
            "[3460] train_loss=3.3611 val_loss=2.5462 best_val_loss=1.7825 step_time=5.46s TPS=36034.70 lr=0.000009\n",
            "[3480] train_loss=2.7282 val_loss=1.8496 best_val_loss=1.7825 step_time=5.46s TPS=35994.43 lr=0.000009\n",
            "[3500] train_loss=3.3284 val_loss=2.7424 best_val_loss=1.7825 step_time=5.48s TPS=35895.74 lr=0.000009\n",
            "[3520] train_loss=4.1620 val_loss=3.5996 best_val_loss=1.7825 step_time=5.46s TPS=35991.40 lr=0.000009\n",
            "[3540] train_loss=3.7082 val_loss=3.2807 best_val_loss=1.7825 step_time=5.48s TPS=35890.27 lr=0.000009\n",
            "[3560] train_loss=4.0674 val_loss=3.6960 best_val_loss=1.7825 step_time=5.47s TPS=35943.89 lr=0.000009\n",
            "[3580] train_loss=3.4068 val_loss=2.8422 best_val_loss=1.7825 step_time=5.48s TPS=35870.39 lr=0.000009\n",
            "[3600] train_loss=2.9393 val_loss=1.8746 best_val_loss=1.7825 step_time=5.47s TPS=35975.38 lr=0.000009\n",
            "[3620] train_loss=2.6848 val_loss=1.7141 best_val_loss=1.7825 step_time=5.48s TPS=35862.51 lr=0.000009\n",
            "  -> New best model! (val_loss=1.7141)\n",
            "  -> Saved to: checkpoints/best_model_step_3620.pt\n",
            "  -> Removed old: best_model_step_2180.pt\n",
            "[3640] train_loss=2.7779 val_loss=2.0605 best_val_loss=1.7141 step_time=5.47s TPS=35952.68 lr=0.000009\n",
            "[3660] train_loss=3.1323 val_loss=2.0935 best_val_loss=1.7141 step_time=5.47s TPS=35965.24 lr=0.000009\n",
            "[3680] train_loss=2.9201 val_loss=1.9484 best_val_loss=1.7141 step_time=5.47s TPS=35974.26 lr=0.000009\n",
            "[3700] train_loss=3.4484 val_loss=2.4655 best_val_loss=1.7141 step_time=5.49s TPS=35838.14 lr=0.000009\n",
            "[3720] train_loss=3.8847 val_loss=3.3883 best_val_loss=1.7141 step_time=5.48s TPS=35879.58 lr=0.000009\n",
            "[3740] train_loss=3.9404 val_loss=2.8250 best_val_loss=1.7141 step_time=5.47s TPS=35922.79 lr=0.000009\n",
            "[3760] train_loss=2.6811 val_loss=1.8032 best_val_loss=1.7141 step_time=5.49s TPS=35810.55 lr=0.000009\n",
            "[3780] train_loss=2.4486 val_loss=1.4801 best_val_loss=1.7141 step_time=5.47s TPS=35911.26 lr=0.000009\n",
            "  -> New best model! (val_loss=1.4801)\n",
            "  -> Saved to: checkpoints/best_model_step_3780.pt\n",
            "  -> Removed old: best_model_step_3620.pt\n",
            "[3800] train_loss=2.3907 val_loss=1.3835 best_val_loss=1.4801 step_time=5.49s TPS=35790.93 lr=0.000009\n",
            "  -> New best model! (val_loss=1.3835)\n",
            "  -> Saved to: checkpoints/best_model_step_3800.pt\n",
            "  -> Removed old: best_model_step_3780.pt\n",
            "[3820] train_loss=2.4843 val_loss=1.5330 best_val_loss=1.3835 step_time=5.50s TPS=35723.58 lr=0.000009\n",
            "[3840] train_loss=2.3161 val_loss=1.4746 best_val_loss=1.3835 step_time=5.54s TPS=35492.41 lr=0.000009\n",
            "[3860] train_loss=2.5477 val_loss=1.8953 best_val_loss=1.3835 step_time=5.50s TPS=35738.70 lr=0.000009\n",
            "[3880] train_loss=2.7310 val_loss=1.6422 best_val_loss=1.3835 step_time=5.50s TPS=35753.45 lr=0.000009\n",
            "[3900] train_loss=2.9662 val_loss=1.9149 best_val_loss=1.3835 step_time=5.49s TPS=35803.12 lr=0.000009\n",
            "[3920] train_loss=2.6158 val_loss=1.6887 best_val_loss=1.3835 step_time=5.47s TPS=35937.59 lr=0.000009\n",
            "[3940] train_loss=2.4890 val_loss=1.4498 best_val_loss=1.3835 step_time=5.49s TPS=35812.59 lr=0.000008\n",
            "[3960] train_loss=2.5085 val_loss=1.4537 best_val_loss=1.3835 step_time=5.49s TPS=35842.89 lr=0.000008\n",
            "[3980] train_loss=2.2803 val_loss=1.3837 best_val_loss=1.3835 step_time=5.51s TPS=35669.13 lr=0.000008\n",
            "[4000] train_loss=2.3962 val_loss=1.5109 best_val_loss=1.3835 step_time=5.51s TPS=35709.96 lr=0.000008\n",
            "[4020] train_loss=2.9201 val_loss=2.5809 best_val_loss=1.3835 step_time=5.51s TPS=35678.23 lr=0.000008\n",
            "[4040] train_loss=3.4248 val_loss=2.4934 best_val_loss=1.3835 step_time=5.50s TPS=35717.38 lr=0.000008\n",
            "[4060] train_loss=2.5736 val_loss=1.7170 best_val_loss=1.3835 step_time=5.50s TPS=35744.63 lr=0.000008\n",
            "[4080] train_loss=2.1610 val_loss=1.4465 best_val_loss=1.3835 step_time=5.48s TPS=35902.97 lr=0.000008\n",
            "[4100] train_loss=2.0552 val_loss=1.3423 best_val_loss=1.3835 step_time=5.52s TPS=35634.79 lr=0.000008\n",
            "  -> New best model! (val_loss=1.3423)\n",
            "  -> Saved to: checkpoints/best_model_step_4100.pt\n",
            "  -> Removed old: best_model_step_3800.pt\n",
            "[4120] train_loss=2.1362 val_loss=1.2541 best_val_loss=1.3423 step_time=5.50s TPS=35771.72 lr=0.000008\n",
            "  -> New best model! (val_loss=1.2541)\n",
            "  -> Saved to: checkpoints/best_model_step_4120.pt\n",
            "  -> Removed old: best_model_step_4100.pt\n",
            "[4140] train_loss=2.0429 val_loss=1.2662 best_val_loss=1.2541 step_time=5.52s TPS=35622.23 lr=0.000008\n",
            "[4160] train_loss=2.1715 val_loss=1.3775 best_val_loss=1.2541 step_time=5.51s TPS=35713.07 lr=0.000008\n",
            "[4180] train_loss=2.6436 val_loss=2.1064 best_val_loss=1.2541 step_time=5.52s TPS=35641.90 lr=0.000008\n",
            "[4200] train_loss=3.9576 val_loss=3.4678 best_val_loss=1.2541 step_time=6.44s TPS=30543.50 lr=0.000008\n",
            "[4220] train_loss=3.8557 val_loss=3.4789 best_val_loss=1.2541 step_time=5.53s TPS=35530.37 lr=0.000008\n",
            "[4240] train_loss=3.8149 val_loss=3.3624 best_val_loss=1.2541 step_time=5.52s TPS=35620.77 lr=0.000008\n",
            "[4260] train_loss=3.8021 val_loss=3.3517 best_val_loss=1.2541 step_time=5.52s TPS=35638.18 lr=0.000008\n",
            "[4280] train_loss=3.7699 val_loss=3.3572 best_val_loss=1.2541 step_time=5.52s TPS=35636.00 lr=0.000008\n",
            "[4300] train_loss=3.5951 val_loss=3.1980 best_val_loss=1.2541 step_time=5.57s TPS=35297.44 lr=0.000008\n",
            "[4320] train_loss=3.1894 val_loss=2.2147 best_val_loss=1.2541 step_time=5.53s TPS=35520.90 lr=0.000008\n",
            "[4340] train_loss=2.1627 val_loss=1.3470 best_val_loss=1.2541 step_time=5.54s TPS=35501.48 lr=0.000008\n",
            "[4360] train_loss=1.8918 val_loss=1.1894 best_val_loss=1.2541 step_time=5.52s TPS=35605.19 lr=0.000008\n",
            "  -> New best model! (val_loss=1.1894)\n",
            "  -> Saved to: checkpoints/best_model_step_4360.pt\n",
            "  -> Removed old: best_model_step_4120.pt\n",
            "[4380] train_loss=1.8958 val_loss=1.0435 best_val_loss=1.1894 step_time=5.53s TPS=35547.58 lr=0.000008\n",
            "  -> New best model! (val_loss=1.0435)\n",
            "  -> Saved to: checkpoints/best_model_step_4380.pt\n",
            "  -> Removed old: best_model_step_4360.pt\n",
            "[4400] train_loss=1.6996 val_loss=1.0496 best_val_loss=1.0435 step_time=5.55s TPS=35419.70 lr=0.000008\n",
            "[4420] train_loss=1.7796 val_loss=0.8917 best_val_loss=1.0435 step_time=5.51s TPS=35710.18 lr=0.000008\n",
            "  -> New best model! (val_loss=0.8917)\n",
            "  -> Saved to: checkpoints/best_model_step_4420.pt\n",
            "  -> Removed old: best_model_step_4380.pt\n",
            "[4440] train_loss=1.5649 val_loss=0.9386 best_val_loss=0.8917 step_time=5.54s TPS=35493.46 lr=0.000008\n",
            "[4460] train_loss=1.7023 val_loss=0.9218 best_val_loss=0.8917 step_time=5.55s TPS=35456.20 lr=0.000008\n",
            "[4480] train_loss=1.7594 val_loss=0.8930 best_val_loss=0.8917 step_time=5.52s TPS=35629.46 lr=0.000008\n",
            "[4500] train_loss=1.6651 val_loss=0.9334 best_val_loss=0.8917 step_time=5.53s TPS=35561.83 lr=0.000008\n",
            "[4520] train_loss=1.7992 val_loss=1.0046 best_val_loss=0.8917 step_time=5.54s TPS=35464.52 lr=0.000008\n",
            "[4540] train_loss=1.7313 val_loss=1.0982 best_val_loss=0.8917 step_time=5.54s TPS=35457.32 lr=0.000008\n",
            "[4560] train_loss=2.0625 val_loss=1.1530 best_val_loss=0.8917 step_time=5.55s TPS=35445.70 lr=0.000008\n",
            "[4580] train_loss=3.0260 val_loss=2.3402 best_val_loss=0.8917 step_time=5.55s TPS=35423.12 lr=0.000008\n",
            "[4600] train_loss=2.4906 val_loss=1.6907 best_val_loss=0.8917 step_time=5.55s TPS=35405.29 lr=0.000008\n",
            "[4620] train_loss=2.0472 val_loss=1.2998 best_val_loss=0.8917 step_time=5.54s TPS=35512.46 lr=0.000008\n",
            "[4640] train_loss=1.7659 val_loss=1.0005 best_val_loss=0.8917 step_time=5.55s TPS=35441.60 lr=0.000008\n",
            "[4660] train_loss=1.5829 val_loss=0.9931 best_val_loss=0.8917 step_time=5.55s TPS=35453.65 lr=0.000008\n",
            "[4680] train_loss=1.6199 val_loss=0.8481 best_val_loss=0.8917 step_time=5.57s TPS=35282.53 lr=0.000008\n",
            "  -> New best model! (val_loss=0.8481)\n",
            "  -> Saved to: checkpoints/best_model_step_4680.pt\n",
            "  -> Removed old: best_model_step_4420.pt\n",
            "[4700] train_loss=1.5719 val_loss=0.8522 best_val_loss=0.8481 step_time=5.53s TPS=35570.51 lr=0.000008\n",
            "[4720] train_loss=1.5597 val_loss=0.8055 best_val_loss=0.8481 step_time=5.56s TPS=35386.46 lr=0.000007\n",
            "  -> New best model! (val_loss=0.8055)\n",
            "  -> Saved to: checkpoints/best_model_step_4720.pt\n",
            "  -> Removed old: best_model_step_4680.pt\n",
            "[rank0]: Traceback (most recent call last):\n",
            "[rank0]:   File \"/content/Tiny-R2/train.py\", line 717, in <module>\n",
            "[rank0]:     train(args)\n",
            "[rank0]:   File \"/content/Tiny-R2/train.py\", line 585, in train\n",
            "[rank0]:     scaler.scale(loss).backward()\n",
            "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\", line 630, in backward\n",
            "[rank0]:     torch.autograd.backward(\n",
            "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\", line 364, in backward\n",
            "[rank0]:     _engine_run_backward(\n",
            "[rank0]:   File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\", line 865, in _engine_run_backward\n",
            "[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "[rank0]: KeyboardInterrupt\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mopenwebtext\u001b[0m at: \u001b[34mhttps://wandb.ai/yingjun-xuda/Tiny-R2-openweb/runs/dpozko59\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20260225_071351-dpozko59/logs\u001b[0m\n",
            "[rank0]:[W225 09:45:02.268858771 ProcessGroupNCCL.cpp:1553] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python train.py --n_layer 12 --n_embd 384 --hc 'True' --mhc 'True' --n_experts 32  --max_iters 10000 --attention_types 'Spares' --batch_size 16 --ctx_len 1536 --hf_dataset 'Skylion007/openwebtext' --resume True --save_best_only True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py --checkpoint checkpoints/best_model_step_4720.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuBClWyiMFHf",
        "outputId": "c3b82b6d-7ab0-44bd-beb8-42b069862c8b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Loading model from checkpoints/best_model_step_4720.pt...\n",
            "Found 'model' key in checkpoint, step: unknown\n",
            "Checkpoint vocab size: 50257\n",
            "Model loaded successfully.\n",
            "\n",
            "Using GPT-2 tokenizer\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "Running quick test...\n",
            "  Input shape: torch.Size([1, 10])\n",
            "  Output shape: torch.Size([1, 10, 50257])\n",
            "  Output type: <class 'torch.Tensor'>\n",
            "  Test passed!\n",
            "\n",
            "Loading WikiText-103 dataset...\n",
            "Evaluating on full test set (4358 samples)...\n",
            "Context length: 1536, stride: 768\n",
            "\n",
            "Evaluating: 100% 4358/4358 [02:15<00:00, 32.14it/s]\n",
            "\n",
            "============================================================\n",
            "WikiText-103 Evaluation Results\n",
            "============================================================\n",
            "Perplexity:           4.13\n",
            "Average Loss:         1.4195\n",
            "Bits per Character:   2.0479\n",
            "Total Tokens:         280,396\n",
            "============================================================\n",
            "\n",
            "Reference values:\n",
            "  GPT-2 Small (124M): ~16.3 PPL\n",
            "  GPT-2 Medium (345M): ~12.0 PPL\n",
            "  GPT-2 Large (774M): ~10.6 PPL\n",
            "\n",
            "Results saved to wikitext103_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D8lcuW-T3DUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bIKpEo6Ju4Sh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe349456-c4f3-48ea-e4f1-ff7301e7979a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from checkpoints/best_model_step_4720.pt...\n",
            "Model loaded successfully.\n",
            "Tokenizer not found, using GPT-2 tokenizer\n",
            "===== Generated Text =====\n",
            "Today is sun . - out out, else Championread Barry unfoldsatic exodus ( fun soon enough ship impossible up high City handed place many Super International months years Add out race ridden similarly similarly looking hints per there are working crappy responsibility want want mature derived out of the right fossils school Hall Case facts went picked up lot lot Houston witness Canterbury PompeOperation half Dec ch probe,, who also well contained personality forced out talked dropped arrived out so many quickly burden crop probe creditslam return Dick Wright St per lot blue out still still highly\n",
            "KV Cache Size (GB): 0.0000\n"
          ]
        }
      ],
      "source": [
        "!python sampler.py --checkpoint checkpoints/best_model_step_4720.pt --prompt \"Today is sun . \"  --max_new_tokens 100 --temperature 0.7    --top_k 100     --device cuda"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "G4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPO5cw+aNoLTPuoiKgbyFWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
